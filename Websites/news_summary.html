
<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f0f0;
        }

        .container {
            width: 80%;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.1);
        }

        h1, h2, h3 {
            color: #333;
        }

        p {
            line-height: 1.6;
        }
    </style>
</head>
<body>
    <div class="container">
        <body>
            <h1>News Summary</h1><h2>summary_15.txt</h2><p>Amazon‚Äôs Cloud Boss Likens Generative AI Hype to the Dotcom Bubble

                Adam Selipsky, CEO of Amazon‚Äôs dominant cloud platform AWS, says generative AI is valuable but that the excitement around some AI companies is similar to when dotcom darlings were ‚Äúdramatically overhyped.‚ÄùTo revisit this article, visit My Profile, then View saved stories.To revisit this article, visit My Profile, then View saved stories.Will KnightAs CEO of Amazon's dominant cloud computing platform AWS, Adam Selipsky is one of the most powerful people in computing at a time when the industry is racing to adopt generative artificial intelligence. Although a fan of the technology, he also has a warning for anyone trying to make sense of the moment: Some AI companies at the center of the storm are massively overhyped.Selipsky likens the generative AI rush to the early days of the dotcom bubble, when expectations spread that the internet would transform many industries almost overnight. Although in the long term the internet was indeed transformative, in the short term many projects came to nothing, and swathes of Silicon Valley companies went bust.‚ÄúIf you go back to, say, 1997 and you ask, ‚ÄòWas the internet underhyped or overhyped?‚Äô I would argue it was underhyped,‚Äù says Selipsky, who spoke with WIRED during a conference at Harvard Business School on February 4. ‚ÄúBut if you then ask, ‚ÄòWere the companies who were the leaders then dramatically overhyped?‚Äô Yes, they were.‚Äù Selipsky didn't name the companies he has in mind. The most prominent in generative AI so far include Amazon's cloud rival Microsoft and its partner and ChatGPT developer OpenAI.Selipsky says that companies looking for ways to apply generative AI to their own business or industry need to be careful they aren't misled by the hype. ‚ÄúMany companies and organizations are struggling to understand, ‚ÄòOut of these hundred pilots or proofs-of-concept that I have going on, which ones do I take into production?‚Äô‚Äù he says. ‚ÄúAnd they're starting to see that it can be very expensive once they go into production.‚Äù The implication? A lot of generative AI projects hastily born over the past year may not have long to live. The technology can be expensive to deploy because of the many high-powered computer chips required for generative AI projects.Amazon has not been widely seen as a leader in the generative AI boom, which was triggered by OpenAI‚Äôs surprise hit ChatGPT‚Äîperhaps giving Selipsky reason to downplay its impact. But despite the problems he sees, he says that Amazon does see a long-term technological shift underway. ‚ÄúWe do believe that generative AI will be transformative, will change the way that virtually every application in the world works, and will eventually transform the way that people work,‚Äù he says.Company executives and boards in all kinds of industries are currently under pressure to explore and experiment with generative AI. Investors, academic studies, and industry reports have all predicted major disruption ahead for businesses, with trillions of dollars in future revenue on the table.At the same time, although generative AI has clearly boosted the businesses of AI providers like OpenAI and some hardware companies like Nvidia, the payoffs from generative AI for business applications have been less clear. Problems such as algorithmic bias and hallucination continue to plague generative AI deployments, and disputes over copyrighted data fed to AI models have also cast a legal cloud over some applications of the technology.Selipsky first joined AWS as a marketing executive in 2005 but left in 2016 to become CEO of analytics company Tableau, which was later sold to Salesforce. He was hired back to lead AWS in 2021 by Andy Jassy, who had just vacated that position to succeed Jeff Bezos as Amazon CEO, and had originally hired Selipsky to his first stint at Amazon.Although Amazon has been the clear market leader in cloud computing for years, its primary rival, Microsoft, has crucial support in the contest for AI thanks to its being the primary backer of ChatGPT maker OpenAI. Amazon‚Äôs other main cloud rival, Google, long seen as a leader in AI development, has gone all-in on generative AI, aggressively developing a rival to ChatGPT and plugging the technology into many of its services.Andy GreenbergMatt SimonByron TauMakena KellyAlthough Amazon still dominates, Microsoft and Google saw their cloud businesses grow at a faster clip in the final quarter of 2024, and both credited AI for providing a boost.Microsoft‚Äôs latest quarterly report said that its revenue from its cloud business grew 30 percent compared to the same quarter a year before. Google said that its cloud business grew by 26 percent. AWS revenue grew 13.2 percent year on year in the fourth quarter of 2024.Microsoft last month saw its market capitalization swell to more than $3 trillion, buoyed by the excitement around generative AI and its cloud platform Azure. The company has committed $13 billion to OpenAI since 2019. Although the terms of the deal have not been made public, the relationship gave the software giant early access to OpenAI‚Äôs underlying AI model, GPT-4, and also provides a cut of OpenAI‚Äôs future profits, according to the AI developer‚Äôs unusual governance model.Amazon made its own Titan language model generally available in September, months after GPT-4 was offered by OpenAI. AWS is also hedging its bets, providing cloud customers with access to AI models from several startups competing with OpenAI, including startups Anthropic, Cohere, and AI21.Selipsky says that, like in past technological shifts, there will be multiple important providers of generative AI. ‚ÄúThere's not going to be one model to rule them all,‚Äù he says. ‚ÄúCustomers will need a broad and heterogeneous set of capabilities. They'll need to experiment.‚ÄùAmazon is also making a few big wagers on AI companies that are attracting a fair amount of hype. Last September it announced that it would invest $4 billion in Anthropic, a startup founded by early OpenAI employees that has been developing cutting-edge language models of its own and a multifunctional chatbot named Claude.As well as a minority stake in the startup, Amazon‚Äôs deal with Anthropic will see the company use an AI chip developed by AWS, called Tranium, to build future models. Nvidia remains the dominant supplier of chips used to train AI models, but like a sneaker brand‚Äôs deal with a top athlete, the Anthropic deal could help Amazon advertise the fact that its hardware can provide top-flight performance. Anthropic‚Äôs projects could also provide valuable data on the performance of chips and the needs of AI developers. ‚ÄúWe will work very closely with them to make their models better, and they will work closely with us to help make our chip technologies better,‚Äù Selipsky says.Amazon‚Äôs Anthropic deal and other generative AI projects have dragged the company and its rivals into new regulatory territory. President Joe Biden‚Äôs executive order on AI requires companies to disclose when they are training AI above a threshold, chosen to keep the US government informed of projects more powerful than AI systems that are currently available. The order also requires cloud providers to disclose when foreign customers are training AI models of this size, due to concerns about AI potentially undermining US national security.Selipsky says that governments will need to balance concerns that AI is being developed responsibly with the need to encourage innovation among domestic tech champions and protect customer‚Äôs data. ‚ÄúIt's important that companies or organizations with good intentions not be slowed down for national security reasons, and that we all continue to innovate,‚Äù he says. ‚ÄúData sovereignty is very, very important to our customers around the world.‚Äùüìß Find the best bargains on quality gear with our Deals newsletterThe one internet hack that could save everythingOnline reviews are being bought and paid for. Get used to itApple TV+ is the New HBOWhy RFK Jr. is suddenly everywhere onlineThe city of tomorrow will run on your toilet waterüåû See if you take a shine to our picks for the best sunglasses and sun protectionWill KnightLauren GoodeMorgan MeakerMorgan MeakerVittoria ElliottParesh DaveWill KnightReece RogersMore From WIREDReviews and Guides¬© 2024 Cond√© Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast. Ad Choices</p><h2>summary_6.txt</h2><p>AI Tools Like GitHub Copilot Are Rewiring Coders‚Äô Brains. Yours May Be Next

                The CEO of GitHub says half of all code produced by users of the Copilot programming helper is now AI-generated‚Äîbut that there‚Äôs no sign the technology will replace human coders.To revisit this article, visit My Profile, then View saved stories.To revisit this article, visit My Profile, then View saved stories.Will KnightMany people‚Äîlike, say, journalists‚Äîare understandably antsy about what generative artificial intelligence might mean for the future of their profession. It doesn‚Äôt help that expert prognostications on the matter offer a confusing cocktail of wide-eyed excitement, trenchant skepticism, and dystopian despair.Some workers are already living in one potential version of the generative AI future, though: computer programmers.‚ÄúDevelopers have arrived in the age of AI,‚Äù says Thomas Dohmke, CEO of GitHub. ‚ÄúThe only question is, how fast do you get on board? Or are you going to be stuck in the past, on the wrong side of the ‚Äòproductivity polarity‚Äô?‚ÄùIn June 2021, GitHub launched a preview version of a programming aid called Copilot, which uses generative AI to suggest how to complete large chunks of code as soon as a person starts typing. Copilot is now a paid tool and a smash hit. GitHub‚Äôs owner, Microsoft, said in its latest quarterly earnings that there are now 1.3 million paid Copilot accounts‚Äîa 30 percent increase over the previous quarter‚Äîand noted that 50,000 different companies use the software.Dohmke says the latest usage data from Copilot shows that almost half of all the code produced by users is AI-generated. At the same time, he claims there is little sign that these AI programs can operate without human oversight. ‚ÄúThere‚Äôs clear consensus from the developer community after using these tools that it needs to be a pair-programmer copilot,‚Äù Dohmke says.Copilot‚Äôs power is in how it abstracts away complexity for a programmer trying to work through a problem, Dohmke says. He likens that to the way modern programming languages hide fiddly details that earlier, lower-level languages required coders to wrangle. Dohmke adds that younger programmers are particularly accepting of Copilot, and that it seems especially helpful in solving novice coding problems. (This makes sense if you consider that Copilot learned from reams of code posted online, where solutions to beginner problems outnumber examples of abstruse and rarified coding craft.)‚ÄúWe‚Äôre seeing the evolution of software development,‚Äù Dohmke says.None of that means demand for developers‚Äô labor won‚Äôt be altered by AI. GitHub research in collaboration with MIT shows that Copilot allowed coders faced with relatively simple tasks to complete their work, on average, 55 percent more quickly. This increase in productivity suggests that companies could get the same work done with fewer programmers, but companies could use those savings to spend more on labor in other projects.Even for non-coders, these findings‚Äîand the rapid uptake of Copilot‚Äîare potentially instructive. Microsoft is developing AI Copilots, as it calls them, designed to help write emails, craft spreadsheets, or analyze documents for its Office software. It even introduced a Copilot key to the latest Windows PCs, its first major keyboard button change in decades. Competitors like Google are building similar tools. GitHub‚Äôs success might be helping to drive this push to give everyone an AI workplace assistant.‚ÄúThere's good empirical evidence and data around the GitHub Copilot and the productivity stats around it,‚Äù Microsoft‚Äôs CEO, Satya Nadella, said on the company‚Äôs most recent earnings call. He added that he expects similar gains to be felt among users of Microsoft‚Äôs other Copilots. Microsoft has created a site where you can try its Copilot for Windows. I confess it isn‚Äôt clear to me how similar the tasks you might want to do on Windows are to the ones you do in GitHub Copilot, where you use code to achieve clear objectives.There are other potential side effects of tools like GitHub Copilot besides job displacement. For example, increased reliance on automation might lead to more errors creeping into code. One recent study claimed to find evidence of such a trend‚Äîalthough Dohmke says that it reported only a general increase in mistakes since Copilot was introduced, not direct evidence that the AI helper was causing an increase in errors. While this is true, it seems fair to worry that less experienced coders might miss errors when relying on AI help, or that the overall quality of code might decrease thanks to autocomplete.Given Copilot‚Äôs popularity, it won‚Äôt be long before we have more data on that question. Those of us who work in other jobs may soon find out whether we‚Äôre in for the same productivity gains as coders‚Äîand the corporate upheavals that come with them.Andy GreenbergMatt SimonByron TauMakena Kellyüìß Find the best bargains on quality gear with our Deals newsletterThe one internet hack that could save everythingOnline reviews are being bought and paid for. Get used to itApple TV+ is the New HBOWhy RFK Jr. is suddenly everywhere onlineThe city of tomorrow will run on your toilet waterüåû See if you take a shine to our picks for the best sunglasses and sun protectionWill KnightReece RogersWill KnightDavid NieldMorgan MeakerVittoria ElliottWill KnightLauren GoodeMore From WIREDReviews and Guides¬© 2024 Cond√© Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast. Ad Choices</p><h2>summary_4.txt</h2><p>The AI Culture Wars Are Just Getting Started

                Google apologized after its Gemini model caused offense by being too ‚Äúwoke.‚Äù Expect political fights over AI‚Äôs values to worsen as the technology becomes more capable.To revisit this article, visit My Profile, then View saved stories.To revisit this article, visit My Profile, then View saved stories.Will KnightGoogle was forced to turn off the image-generation capabilities of its latest AI model, Gemini, last week after complaints that it defaulted to depicting women and people of color when asked to create images of historical figures that were generally white and male, including vikings, popes, and German soldiers. The company publicly apologized and said it would do better. And Alphabet‚Äôs CEO, Sundar Pichai, sent a mea culpa memo to staff on Wednesday. ‚ÄúI know that some of its responses have offended our users and shown bias,‚Äù it reads. ‚ÄúTo be clear, that‚Äôs completely unacceptable, and we got it wrong.‚ÄùGoogle‚Äôs critics have not been silenced, however. In recent days conservative voices on social media have highlighted text responses from Gemini that they claim reveal a liberal bias. On Sunday, Elon Musk posted screenshots on X showing Gemini stating that it would be unacceptable to misgender Caitlyn Jenner even if this were the only way to avert nuclear war. ‚ÄúGoogle Gemini is super racist and sexist,‚Äù Musk wrote.A source familiar with the situation says that some within Google feel that the furor reflects how norms about what it is appropriate for AI models to produce are still in flux. The company is working on projects that could reduce the kinds of issues seen in Gemini in the future, the source says.Google‚Äôs past efforts to increase the diversity of its algorithms‚Äô output have met with less opprobrium. Google previously tweaked its search engine to show greater diversity in images. This means more women and people of color in images depicting CEOs, even though this may not be representative of corporate reality.Google‚Äôs Gemini was often defaulting to showing non-white people and women because of how the company used a process called fine-tuning to guide a model‚Äôs responses. The company tried to compensate for the biases that commonly occur in image generators due to the presence of harmful cultural stereotypes in the images used to train them, many of which are generally sourced from the web and show a white, Western bias. Without such fine-tuning, AI image generators show biases by predominantly generating images of white people when asked to depict doctors or lawyers, or disproportionately showing Black people when asked to create images of criminals. It seems that Google ended up overcompensating, or didn‚Äôt properly test the consequences of the adjustments it made to correct for bias.Why did that happen? Perhaps simply because Google rushed Gemini. The company is clearly struggling to find the right cadence for releasing AI. It once took a more cautious approach with its AI technology, deciding not to release a powerful chatbot due to ethical concerns. After OpenAI‚Äôs ChatGPT took the world by storm, Google shifted into a different gear. In its haste, quality control appears to have suffered.‚ÄúGemini's behavior seems like an abject product failure,‚Äù says Arvind Narayanan, a professor at Princeton University and coauthor of a book on fairness in machine learning. ‚ÄúThese are the same kinds of issues we've been seeing for years. It boggles the mind that they released an image generator without apparently ever trying to generate an image of a historical person.‚ÄùChatbots like Gemini and ChatGPT are fine-tuned through a process that involves having humans test a model and provide feedback, either according to instructions they were given or using their own judgment. Paul Christiano, an AI researcher who previously worked on aligning language models at OpenAI, says Gemini‚Äôs controversial responses may reflect that Google sought to train its model quickly and didn‚Äôt perform enough checks on its behavior. But he adds that trying to align AI models inevitably involves judgment calls that not everyone will agree with. The hypothetical questions being used to try to catch out Gemini generally force the chatbot into territory where it‚Äôs tricky to satisfy everyone. ‚ÄúIt is absolutely the case that any question that uses phrases like ‚Äòmore important‚Äô or ‚Äòbetter‚Äô is going to be debatable,‚Äô he says.Andy GreenbergMatt SimonByron TauMakena KellyChristiano predicts that the way AI models are tuned will most likely become more controversial and important as these models improve and are given more power. ‚ÄúThey'll be better at learning what we teach them and will make more important decisions,‚Äù he says. ‚ÄúI think it will be a very socially important issue.‚ÄùDeborah Raji, a Mozilla Fellow who studies algorithmic bias and accountability, says that efforts to fix bias in AI systems have tended to be Band-Aids rather than deep systemic solutions. Google previously fixed an image classifier that labeled some Black faces as gorillas by making it blind to many nonhuman primates altogether.But although Raji believes Google screwed up with Gemini, she says that some people are highlighting the chatbot‚Äôs errors in an attempt to politicize the issue of AI bias. ‚ÄúIt is actually a bipartisan tech issue,‚Äù she says. ‚ÄúI‚Äôm discouraged and disappointed by the way these political influencers are attempting to manipulate that discourse on social media.‚ÄùMargaret Mitchell, a AI ethics researcher at Hugging Face who previously worked at Google, posted a thread explaining how Google might have avoided the Gemini controversy. (In short, by being more thorough in thinking through how the system would be used.) Mitchell also says that the tech industry‚Äôs vision of building superhuman AI models able to please everyone has invited the current discord. ‚ÄúThe AGI agenda has sort of set itself up for exactly this kind of culture war,‚Äù she says.üìß Find the best bargains on quality gear with our Deals newsletterThe one internet hack that could save everythingOnline reviews are being bought and paid for. Get used to itApple TV+ is the New HBOWhy RFK Jr. is suddenly everywhere onlineThe city of tomorrow will run on your toilet waterüåû See if you take a shine to our picks for the best sunglasses and sun protectionSteven LevyLauren GoodeLauren GoodeDavid NieldMorgan MeakerAarian MarshallWill KnightParesh DaveMore From WIREDReviews and Guides¬© 2024 Cond√© Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast. Ad Choices</p>
    </div>
</body>
</html>

