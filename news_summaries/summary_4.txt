The AI Culture Wars Are Just Getting Started

Google apologized after its Gemini model caused offense by being too â€œwoke.â€ Expect political fights over AIâ€™s values to worsen as the technology becomes more capable.To revisit this article, visit My Profile, then View saved stories.To revisit this article, visit My Profile, then View saved stories.Will KnightGoogle was forced to turn off the image-generation capabilities of its latest AI model, Gemini, last week after complaints that it defaulted to depicting women and people of color when asked to create images of historical figures that were generally white and male, including vikings, popes, and German soldiers. The company publicly apologized and said it would do better. And Alphabetâ€™s CEO, Sundar Pichai, sent a mea culpa memo to staff on Wednesday. â€œI know that some of its responses have offended our users and shown bias,â€ it reads. â€œTo be clear, thatâ€™s completely unacceptable, and we got it wrong.â€Googleâ€™s critics have not been silenced, however. In recent days conservative voices on social media have highlighted text responses from Gemini that they claim reveal a liberal bias. On Sunday, Elon Musk posted screenshots on X showing Gemini stating that it would be unacceptable to misgender Caitlyn Jenner even if this were the only way to avert nuclear war. â€œGoogle Gemini is super racist and sexist,â€ Musk wrote.A source familiar with the situation says that some within Google feel that the furor reflects how norms about what it is appropriate for AI models to produce are still in flux. The company is working on projects that could reduce the kinds of issues seen in Gemini in the future, the source says.Googleâ€™s past efforts to increase the diversity of its algorithmsâ€™ output have met with less opprobrium. Google previously tweaked its search engine to show greater diversity in images. This means more women and people of color in images depicting CEOs, even though this may not be representative of corporate reality.Googleâ€™s Gemini was often defaulting to showing non-white people and women because of how the company used a process called fine-tuning to guide a modelâ€™s responses. The company tried to compensate for the biases that commonly occur in image generators due to the presence of harmful cultural stereotypes in the images used to train them, many of which are generally sourced from the web and show a white, Western bias. Without such fine-tuning, AI image generators show biases by predominantly generating images of white people when asked to depict doctors or lawyers, or disproportionately showing Black people when asked to create images of criminals. It seems that Google ended up overcompensating, or didnâ€™t properly test the consequences of the adjustments it made to correct for bias.Why did that happen? Perhaps simply because Google rushed Gemini. The company is clearly struggling to find the right cadence for releasing AI. It once took a more cautious approach with its AI technology, deciding not to release a powerful chatbot due to ethical concerns. After OpenAIâ€™s ChatGPT took the world by storm, Google shifted into a different gear. In its haste, quality control appears to have suffered.â€œGemini's behavior seems like an abject product failure,â€ says Arvind Narayanan, a professor at Princeton University and coauthor of a book on fairness in machine learning. â€œThese are the same kinds of issues we've been seeing for years. It boggles the mind that they released an image generator without apparently ever trying to generate an image of a historical person.â€Chatbots like Gemini and ChatGPT are fine-tuned through a process that involves having humans test a model and provide feedback, either according to instructions they were given or using their own judgment. Paul Christiano, an AI researcher who previously worked on aligning language models at OpenAI, says Geminiâ€™s controversial responses may reflect that Google sought to train its model quickly and didnâ€™t perform enough checks on its behavior. But he adds that trying to align AI models inevitably involves judgment calls that not everyone will agree with. The hypothetical questions being used to try to catch out Gemini generally force the chatbot into territory where itâ€™s tricky to satisfy everyone. â€œIt is absolutely the case that any question that uses phrases like â€˜more importantâ€™ or â€˜betterâ€™ is going to be debatable,â€™ he says.Andy GreenbergMatt SimonByron TauMakena KellyChristiano predicts that the way AI models are tuned will most likely become more controversial and important as these models improve and are given more power. â€œThey'll be better at learning what we teach them and will make more important decisions,â€ he says. â€œI think it will be a very socially important issue.â€Deborah Raji, a Mozilla Fellow who studies algorithmic bias and accountability, says that efforts to fix bias in AI systems have tended to be Band-Aids rather than deep systemic solutions. Google previously fixed an image classifier that labeled some Black faces as gorillas by making it blind to many nonhuman primates altogether.But although Raji believes Google screwed up with Gemini, she says that some people are highlighting the chatbotâ€™s errors in an attempt to politicize the issue of AI bias. â€œIt is actually a bipartisan tech issue,â€ she says. â€œIâ€™m discouraged and disappointed by the way these political influencers are attempting to manipulate that discourse on social media.â€Margaret Mitchell, a AI ethics researcher at Hugging Face who previously worked at Google, posted a thread explaining how Google might have avoided the Gemini controversy. (In short, by being more thorough in thinking through how the system would be used.) Mitchell also says that the tech industryâ€™s vision of building superhuman AI models able to please everyone has invited the current discord. â€œThe AGI agenda has sort of set itself up for exactly this kind of culture war,â€ she says.ğŸ“§ Find the best bargains on quality gear with our Deals newsletterThe one internet hack that could save everythingOnline reviews are being bought and paid for. Get used to itApple TV+ is the New HBOWhy RFK Jr. is suddenly everywhere onlineThe city of tomorrow will run on your toilet waterğŸŒ See if you take a shine to our picks for the best sunglasses and sun protectionSteven LevyLauren GoodeLauren GoodeDavid NieldMorgan MeakerAarian MarshallWill KnightParesh DaveMore From WIREDReviews and GuidesÂ© 2024 CondÃ© Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast. Ad Choices